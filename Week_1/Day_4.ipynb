{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d181abae-2f77-4c34-9ad2-76c960f289cd",
   "metadata": {},
   "source": [
    "# Alignment(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c1a3d7-2942-411b-a781-e3488d8d97eb",
   "metadata": {},
   "source": [
    "The process of ensuring that AI models or agents behave in accordance with human intentions, values, or desired outcomes. (AI Ethics / Reinforcement Learning / Agent Systems)\n",
    "\n",
    "Sentence: Recent research in AI safety emphasizes the importance of model alignment to prevent unintended behavior in autonomous systems.\n",
    "\n",
    "Verb: Align\n",
    "\n",
    "Adjective: Aligned / Aligning\n",
    "\n",
    "Collocations:\n",
    "\n",
    "human(n) **alignment**\n",
    "\n",
    "policy(n) **alignment**\n",
    "\n",
    "agent(n) **alignment**\n",
    "\n",
    "goal(n) **alignment**\n",
    "\n",
    "model(n) **alignment**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58aec0f2-2882-43f7-b591-dd2bea9a6d14",
   "metadata": {},
   "source": [
    "# Conditioning(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28eafe0d-77df-48a7-b2dd-56453b4da276",
   "metadata": {},
   "source": [
    "A method of guiding generative models by providing additional input signals or constraints, such as text prompts or feature maps. (Machine Learning / Generative Modeling)\n",
    "\n",
    "Sentence: The diffusion model generates more accurate visual outputs when strong text-based conditioning is applied.\n",
    "\n",
    "Verb: Condition\n",
    "\n",
    "Adjective: Conditional / conditioned\n",
    "\n",
    "Collocations:\n",
    "\n",
    "text-based(adj) **conditioning**\n",
    "\n",
    "latent(n) **conditioning**\n",
    "\n",
    "**conditional** generation(n)\n",
    "\n",
    "feature(n) **conditioning**\n",
    "\n",
    "guided(adj) **conditioning**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3258c94-fec7-4db0-b236-7b807200b4d6",
   "metadata": {},
   "source": [
    "# Emergence(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0af639-aefe-405e-a9a7-c7ce934b048b",
   "metadata": {},
   "source": [
    "A phenomenon where complex behaviors or properties arise from simple rules or interactions, often observed in large-scale neural systems or multi-agent environments. (Complex Systems / AI Research)\n",
    "\n",
    "Sentence: The emergence of cooperative behavior among autonomous agents demonstrates the potential of large-scale reinforcement learning.\n",
    "\n",
    "Adjective: Emergent\n",
    "\n",
    "Collocations:\n",
    "\n",
    "behavioral(adj) **emergence**\n",
    "\n",
    "language(n) **emergence**\n",
    "\n",
    "pattern(n) **emergence**\n",
    "\n",
    "**emergent** property\n",
    "\n",
    "complex(adj) **emergence**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67d25de-a135-4de2-a56e-3b0369ec768b",
   "metadata": {},
   "source": [
    "# Grounding(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd09234e-e61c-4bbd-8fd2-55bd674d1984",
   "metadata": {},
   "source": [
    "The process of linking abstract symbols or representations (such as language or concepts) to real-world entities, perceptions, or experiences. (Cognitive Science / AI Agents / Multimodal Learning)\n",
    "\n",
    "Sentence: Effective multimodal grounding enables AI agents to interpret textual commands in the context of their visual environment.\n",
    "\n",
    "Verb: Ground\n",
    "\n",
    "Adjective: Grounded\n",
    "\n",
    "Collocations:\n",
    "\n",
    "Semantic(adj) **grounding**\n",
    "\n",
    "visual(adj) **grounding**\n",
    "\n",
    "language(n) **grounding**\n",
    "\n",
    "world(n) **grouding**\n",
    "\n",
    "perceptual(adj) **grounding**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c385434-160d-4dcd-ad03-3917278b6f7e",
   "metadata": {},
   "source": [
    "# Latency(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43fcee4-a5d2-42ca-b42e-bf3eedbd9466",
   "metadata": {},
   "source": [
    "The delay between input and output in a computational process, often used to measure the efficiency of AI systems or inference pipelines. (Computer Systems / Machine Learning)\n",
    "\n",
    "Sentence: Reducing inference latency is essential for deploying real-time generative models in interactive applications.\n",
    "\n",
    "Ajective: Latent(note: related but distinct term, often used in representation learning)\n",
    "\n",
    "Collocations:\n",
    "\n",
    "inference(n) **latency**\n",
    "\n",
    "network(n) **latency**\n",
    "\n",
    "low(adj) **latency**\n",
    "\n",
    "response(n) **latency**\n",
    "\n",
    "**latency** optimization(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e8b251-8711-4630-8512-0aaaaaf0a8ed",
   "metadata": {},
   "source": [
    "# Reward(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3666fea4-1330-48d2-b249-4d6da81ba88f",
   "metadata": {},
   "source": [
    "A signal that represents feedback for an agent's actions, guiding its learning process through reinforcement mechanisms. (Reinforcement Learning / AI Agents)\n",
    "\n",
    "Sentence: The agent optimizes its policy by maximizing cumulative rewards obtained during the training episodes.\n",
    "\n",
    "Verb: Reward\n",
    "\n",
    "Adjective: Rewarding / Rewarded\n",
    "\n",
    "Collocations:\n",
    "\n",
    "**reward** function(n)\n",
    "\n",
    "**reward** signal(n)\n",
    "\n",
    "extrinsic(adj) **reward**\n",
    "\n",
    "**reward** model(n)\n",
    "\n",
    "**reward** shaping(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d03217-3076-4e5d-926c-d7fa13f8aa89",
   "metadata": {},
   "source": [
    "# Sampling(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71a76d3-68b3-431b-84a2-47d6b6c86985",
   "metadata": {},
   "source": [
    "The process of generating data points or outputs from a probabilistic model, often used in diffusion, GAN, or autoregressive models. (Generative Modeling / Probabilistic AI)\n",
    "\n",
    "Sentence: The quality of synthesized images depends heavily on the sampling strategy used during the diffusion process.\n",
    "\n",
    "Verb: Sample\n",
    "\n",
    "Adjective: Sampled / Sampling\n",
    "\n",
    "Collocations:\n",
    "\n",
    "importance(n) **sampling**\n",
    "\n",
    "stochastic(adj) **sampling**\n",
    "\n",
    "image(n) **sampling**\n",
    "\n",
    "**sampling** procedure(n)\n",
    "\n",
    "**sampling** step(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639637a5-2818-4045-93c8-dc7a422f370b",
   "metadata": {},
   "source": [
    "# Denoising(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8669bc9b-8733-48fd-98ad-76eb1bc0f086",
   "metadata": {},
   "source": [
    "The technique of removing noise from data, often a critical step in diffusion-based generative models. (Machine Learning / Image Generation)\n",
    "\n",
    "Sentence: Each denoising step in the diffusion process refines the image quality by progressively restoring structure and detail.\n",
    "\n",
    "Verb: Denoise\n",
    "\n",
    "Adjective: Denoised / Denoising\n",
    "\n",
    "Collocations:\n",
    "\n",
    "**denoising** process(n)\n",
    "\n",
    "**denoising** model(n)\n",
    "\n",
    "image(n) **denoising**\n",
    "\n",
    "**denoising** step(n)\n",
    "\n",
    "related: noise(n) reduction(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47540b77-bfed-4c0a-913e-ec10f5d591f8",
   "metadata": {},
   "source": [
    "# Latent(adj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82334132-37dc-43f0-be0c-ebb92dbe2d1a",
   "metadata": {},
   "source": [
    "Referring to variables or representations that are hidden or not directly observable, often encoding high-level features in generative models. (Representation Learning / Deep Learning)\n",
    "\n",
    "Sentence: The model maps input images into a latent space where semantic relationships are more easily captured.\n",
    "\n",
    "Noun: Latent (used as noun in \"Latent space\")\n",
    "\n",
    "Collocations:\n",
    "\n",
    "**latent** space(n)\n",
    "\n",
    "**latent** vector(n)\n",
    "\n",
    "**latent** representation(n)\n",
    "\n",
    "**latent** diffusion(n)\n",
    "\n",
    "**latent** variable(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7659688e-0c48-4d86-9303-e0dcd0c2b9f7",
   "metadata": {},
   "source": [
    "# Reconstrucion(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec3167f-d15e-4b7c-a747-49a4dc73c316",
   "metadata": {},
   "source": [
    "The process of generating or recovering an image or signal from its encoded or latent representation. (Computer Vision / Image Generation)\n",
    "\n",
    "Sentence: High-fidelity reconstruction from latent embeddings demonstrates the model's capacity to preserve visual informantion.\n",
    "\n",
    "Verb: Reconstruct\n",
    "\n",
    "Adjective: Reconstructed / Reconstructive\n",
    "\n",
    "Collocations:\n",
    "\n",
    "image(n) **reconstruction**\n",
    "\n",
    "feature(n) **reconstruction**\n",
    "\n",
    "latent(adj) **reconstruction**\n",
    "\n",
    "**reconstruction** quality(n)\n",
    "\n",
    "autoencoder(n) **reconstruction**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
