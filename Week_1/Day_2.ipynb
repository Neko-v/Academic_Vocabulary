{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6ceb891-e017-4c6b-a460-46599bac86c7",
   "metadata": {},
   "source": [
    "# Architecture(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe9407c-8a14-4788-b88e-d4556b4f140c",
   "metadata": {},
   "source": [
    "The overall design or structure of a system, model, or network, especially in computing and AI. (Computer Science / Machine Learning)\n",
    "\n",
    "Sentence: The researchers proposed a novel neural network architechture to improve text-to-image alignment in generative models.\n",
    "\n",
    "Adjective: Architectural\n",
    "\n",
    "Adverb: Architecturally\n",
    "\n",
    "Collocations:\n",
    "\n",
    "neural(adj) +\n",
    "\n",
    "model(n) + \n",
    "\n",
    "system(n) +\n",
    "\n",
    "architecture + design(n)\n",
    "\n",
    "architecture + optimization(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a145d182-21cd-4950-84cf-17e89ad551a2",
   "metadata": {},
   "source": [
    "# Rendering(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5f87ee-1445-421c-85ff-f92b20dfb77a",
   "metadata": {},
   "source": [
    "The process of generating a visual image from a model by means of computer programs. (Computer Graphics / 3DGS / AIGC)\n",
    "\n",
    "Sentence: The paper introduces a fast neural rendering technique for real-time view synthesis in 3D Gaussian Splatting.\n",
    "\n",
    "Verb: Render\n",
    "\n",
    "Adjective: Rendered\n",
    "\n",
    "Collocations:\n",
    "\n",
    "real-time(adj) +\n",
    "\n",
    "photo-realistic(adj) +\n",
    "\n",
    "neural(adj) +\n",
    "\n",
    "perform(v) +\n",
    "\n",
    "accelerate(v) +"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bfd189-a704-4134-8f67-57898125de14",
   "metadata": {},
   "source": [
    "# Feature(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c42e414-3d37-4386-9ec1-3beb07f6339c",
   "metadata": {},
   "source": [
    "An individual measurable property or characteristic used by a model to perform tasks such as classification, detection, or generation. (Machine Learning / Computer Vison)\n",
    "\n",
    "Sentence: The model extracts high-dimensional visual features to improve the accuracy of image synthesis.\n",
    "\n",
    "Verb: Feature\n",
    "\n",
    "Adjective: Feature-based\n",
    "\n",
    "Noun(related): Feature extraction\n",
    "\n",
    "Collocations:\n",
    "\n",
    "visual(adj) +\n",
    "\n",
    "key(adj) +\n",
    "\n",
    "semantic(adj) +\n",
    "\n",
    "extract(v) +\n",
    "\n",
    "encode(v) +"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d32485d-1b14-4591-bb4e-b38532790ad5",
   "metadata": {},
   "source": [
    "# Inference(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66ceb4b-b610-4dda-85b7-7c5b355e6e65",
   "metadata": {},
   "source": [
    "The process of using a trained model to make predictions or generate outputs based on new input data. (Machine Learning / AI)\n",
    "\n",
    "Sentence: During inference, the diffusion model generates realistic images from random noise in just a few steps.\n",
    "\n",
    "Verb: Infer\n",
    "\n",
    "Adjective: Inferential\n",
    "\n",
    "Adverb: Inferentially\n",
    "\n",
    "Collocations:\n",
    "\n",
    "model(n) +\n",
    "\n",
    "neural(adj) +\n",
    "\n",
    "real-time(adj) +\n",
    "\n",
    "perform(v) +\n",
    "\n",
    "accelerate(v) +"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17d1b8b-c1ab-4eb0-b31e-e72f506b6003",
   "metadata": {},
   "source": [
    "# Constraint(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccb000a-6d71-4544-84ca-4d18756b336e",
   "metadata": {},
   "source": [
    "A condition or limitation that restricts the possible solutions or behaviors of a system. (Optimization / Computer Vision / AI Ethics)\n",
    "\n",
    "Sentence: The optimization process incorporates geometric constraints to maintain scene consistency during reconstruction.\n",
    "\n",
    "Verb: Constrain\n",
    "\n",
    "Adjective: Constrained / Constraining\n",
    "\n",
    "Collocations:\n",
    "\n",
    "geometric(adj) +\n",
    "\n",
    "physical(adj) +\n",
    "\n",
    "optimization(n) +\n",
    "\n",
    "impose(v) +\n",
    "\n",
    "apply(v) +"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d86eedd-7ac2-4e89-a80b-dcb1752330cd",
   "metadata": {},
   "source": [
    "# Modality(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049b22af-cac9-4a7c-b10a-4c76d89f2ea3",
   "metadata": {},
   "source": [
    "A particular form or type of data(e.g., text, image, audio) used in multimodal AI system. (AIGC / Deep Learning)\n",
    "\n",
    "Sentence: The model integrates multiple modalities to enhance the coherence between visual and textual content.\n",
    "\n",
    "Adjective: Multimodal\n",
    "\n",
    "Collocations:\n",
    "\n",
    "data(n) +\n",
    "\n",
    "visual(adj) +\n",
    "\n",
    "textual(adj) +\n",
    "\n",
    "combine(v) +\n",
    "\n",
    "align(v) +"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eeca82e-9c54-4c92-9f0a-602c8093ac66",
   "metadata": {},
   "source": [
    "# Pipeline(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7e1c53-e557-4b68-9f02-7a669c9c5284",
   "metadata": {},
   "source": [
    "A sequence of processing steps or components through which data flows to produce a final output. (Machine Learning / Data Engineering)\n",
    "\n",
    "Sentence: The researchers designed an end-to-end pipeline for text-to-3D generation using diffusion models.\n",
    "\n",
    "Adjective: Pipelined\n",
    "\n",
    "Collocations:\n",
    "\n",
    "data(n) +\n",
    "\n",
    "training(n) +\n",
    "\n",
    "processing(n) +\n",
    "\n",
    "design(v) +\n",
    "\n",
    "implement(v) +"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d65444b-0cce-4a11-bdaf-156fd763cb55",
   "metadata": {},
   "source": [
    "# Correspondence(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d807439c-9bd1-4687-811e-08a47a8b63e3",
   "metadata": {},
   "source": [
    "A relationship or mapping between two sets of entities, often used in vision and geometry tasks. (Computer Vision / 3D Reconstruction)\n",
    "\n",
    "Sentence: The algorithm establishes dense point correspondences to align multiple 3D views accurately.\n",
    "\n",
    "Adjective: Corresponding\n",
    "\n",
    "Verb: Correspond\n",
    "\n",
    "Collocations:\n",
    "\n",
    "point(n) +\n",
    "\n",
    "feature(n) +\n",
    "\n",
    "spatial(adj) +\n",
    "\n",
    "establish(v) +\n",
    "\n",
    "compute(v) +"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b0f1c3-0d33-4c46-858d-22276d1b4d7c",
   "metadata": {},
   "source": [
    "# Embedding(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0712b831-8598-4498-b479-40a80fb8e9f6",
   "metadata": {},
   "source": [
    "A numerical representation of data(e.g., text, image, audio) in a continuous vector space. (Deep Learning / Representation Learning)\n",
    "\n",
    "Sentence: The model learns semantic embeddings to capture cross-modal relationships between images and text.\n",
    "\n",
    "Verb: Embed\n",
    "\n",
    "Adjective: Embedded\n",
    "\n",
    "Collocations:\n",
    "\n",
    "semantic(adj) +\n",
    "\n",
    "vector(n) +\n",
    "\n",
    "learn(v) +\n",
    "\n",
    "generate(v) +\n",
    "\n",
    "represent(v) +"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12fb205-3995-4e03-b8d5-ee737bed0df6",
   "metadata": {},
   "source": [
    "# Annotation(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93065c2d-d7b6-4684-9a30-2d741a7b3bee",
   "metadata": {},
   "source": [
    "A label or piece of metadata added to data to provide information used for training or evaluation. (Data Science / Machine Learning)\n",
    "\n",
    "Sentence: The dataset includes fine-grained annotations that enable supervised learning for image segmentation.\n",
    "\n",
    "Verb: Annotate\n",
    "\n",
    "Adjective: Annotated\n",
    "\n",
    "Collocations:\n",
    "\n",
    "manual(adj) +\n",
    "\n",
    "sementic(adj) +\n",
    "\n",
    "dataset(n) +\n",
    "\n",
    "provide(v) +\n",
    "\n",
    "collect(v) +"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
